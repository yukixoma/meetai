/* eslint-disable no-undef */

import { cleanTextForTTS, chunkText } from "../utils/text-cleaner.js";
import { cachedFetch } from "../utils/model-cache.js";
import ort from "onnxruntime-web";
import { phonemize } from "phonemizer";

// Text splitting stream to break text into chunks
export class TextSplitterStream {
    constructor() {
        this.chunks = [];
        this.closed = false;
    }

    chunkText(text) {
        // Clean the text first, then chunk it
        const cleanedText = cleanTextForTTS(text);
        return chunkText(cleanedText);
    }

    push(text) {
        // Simple sentence splitting for now
        const sentences = this.chunkText(text) || [text];
        this.chunks.push(...sentences);
    }

    close() {
        this.closed = true;
    }

    async *[Symbol.asyncIterator]() {
        for (const chunk of this.chunks) {
            yield chunk;
        }
    }
}

// RawAudio class to handle audio data
export class RawAudio {
    constructor(audio, sampling_rate) {
        this.audio = audio;
        this.sampling_rate = sampling_rate;
    }

    get length() {
        return this.audio.length;
    }

    toBlob() {
        // Convert Float32Array to WAV blob
        const buffer = this.encodeWAV(this.audio, this.sampling_rate);
        return new Blob([buffer], { type: "audio/wav" });
    }

    toWav() {
        return this.encodeWAV(this.audio, this.sampling_rate);
    }

    encodeWAV(samples, sampleRate) {
        const buffer = new ArrayBuffer(44 + samples.length * 2);
        const view = new DataView(buffer);

        // RIFF identifier
        this.writeString(view, 0, "RIFF");
        // file length
        view.setUint32(4, 36 + samples.length * 2, true);
        // RIFF type
        this.writeString(view, 8, "WAVE");
        // format chunk identifier
        this.writeString(view, 12, "fmt ");
        // format chunk length
        view.setUint32(16, 16, true);
        // sample format (raw)
        view.setUint16(20, 1, true);
        // channel count
        view.setUint16(22, 1, true);
        // sample rate
        view.setUint32(24, sampleRate, true);
        // byte rate (sample rate * block align)
        view.setUint32(28, sampleRate * 2, true);
        // block align (channel count * bytes per sample)
        view.setUint16(32, 2, true);
        // bits per sample
        view.setUint16(34, 16, true);
        // data chunk identifier
        this.writeString(view, 36, "data");
        // data chunk length
        view.setUint32(40, samples.length * 2, true);

        this.floatTo16BitPCM(view, 44, samples);

        return buffer;
    }

    writeString(view, offset, string) {
        for (let i = 0; i < string.length; i++) {
            view.setUint8(offset + i, string.charCodeAt(i));
        }
    }

    floatTo16BitPCM(output, offset, input) {
        for (let i = 0; i < input.length; i++, offset += 2) {
            const s = Math.max(-1, Math.min(1, input[i]));
            output.setInt16(offset, s < 0 ? s * 0x8000 : s * 0x7fff, true);
        }
    }
}

// Piper TTS class for local model
export class PiperTTS {
    constructor(voiceConfig = null, session = null) {
        this.voiceConfig = voiceConfig;
        this.session = session;
        this.phonemeIdMap = null;
    }

    static async from_pretrained(modelPath, configPath) {
        try {
            ort.env.wasm.wasmPaths =
                "https://cdn.jsdelivr.net/npm/onnxruntime-web@1.23.2/dist/";

            // Load model and config
            const [modelResponse, configResponse] = await Promise.all([
                cachedFetch(modelPath),
                cachedFetch(configPath),
            ]);

            const [modelBuffer, voiceConfig] = await Promise.all([
                modelResponse.arrayBuffer(),
                configResponse.json(),
            ]);

            // Create ONNX session with WASM execution provider
            const session = await ort.InferenceSession.create(modelBuffer, {
                executionProviders: [
                    {
                        name: "wasm",
                        simd: true,
                    },
                ],
            });

            return new PiperTTS(voiceConfig, session);
        } catch (error) {
            console.error("Error loading Piper model:", error);
            throw error;
        }
    }

    // Convert text to phonemes using the phonemizer package
    async textToPhonemes(text) {
        if (this.voiceConfig.phoneme_type === "text") {
            // Text phonemes - just return normalized characters
            return [Array.from(text.normalize("NFD"))];
        }

        // Use phonemizer for espeak-style phonemes
        const voice = this.voiceConfig.espeak?.voice || "en-us";
        const phonemes = await phonemize(text, voice);

        // Handle different return types from phonemizer
        let phonemeText;
        if (typeof phonemes === "string") {
            phonemeText = phonemes;
        } else if (Array.isArray(phonemes)) {
            // Join the array elements - each element is a phonemized sentence
            phonemeText = phonemes.join(" ");
        } else if (phonemes && typeof phonemes === "object") {
            // If it's an object, try to extract text property or convert to string
            phonemeText =
                phonemes.text || phonemes.phonemes || String(phonemes);
        } else {
            console.warn("Unexpected phonemes format:", phonemes);
            phonemeText = String(phonemes || text);
        }

        // Split into sentences and convert to character arrays
        const sentences = phonemeText.split(/[.!?]+/).filter((s) => s.trim());
        return sentences.map((sentence) =>
            Array.from(sentence.trim().normalize("NFD"))
        );
    }

    // Convert phonemes to IDs using the phoneme ID map
    phonemesToIds(textPhonemes) {
        if (!this.voiceConfig || !this.voiceConfig.phoneme_id_map) {
            throw new Error("Phoneme ID map not available");
        }

        const idMap = this.voiceConfig.phoneme_id_map;
        const BOS = "^";
        const EOS = "$";
        const PAD = "_";

        let phonemeIds = [];

        for (let sentencePhonemes of textPhonemes) {
            phonemeIds.push(idMap[BOS]);
            phonemeIds.push(idMap[PAD]);

            for (let phoneme of sentencePhonemes) {
                if (phoneme in idMap) {
                    phonemeIds.push(idMap[phoneme]);
                    phonemeIds.push(idMap[PAD]);
                }
            }

            phonemeIds.push(idMap[EOS]);
        }

        return phonemeIds;
    }

    async *stream(textStreamer, options = {}) {
        const {
            speakerId = 0,
            lengthScale = 1.0,
            noiseScale = 0.667,
            noiseWScale = 0.8,
        } = options;

        // Process the text stream
        for await (const text of textStreamer) {
            if (text.trim()) {
                try {
                    if (this.session && this.voiceConfig) {
                        // Convert text to phonemes then to IDs
                        const textPhonemes = await this.textToPhonemes(text);
                        const phonemeIds = this.phonemesToIds(textPhonemes);

                        const inputs = {
                            input: new ort.Tensor(
                                "int64",
                                new BigInt64Array(
                                    phonemeIds.map((id) => BigInt(id))
                                ),
                                [1, phonemeIds.length]
                            ),
                            input_lengths: new ort.Tensor(
                                "int64",
                                BigInt64Array.from([BigInt(phonemeIds.length)]),
                                [1]
                            ),
                            scales: new ort.Tensor(
                                "float32",
                                Float32Array.from([
                                    noiseScale,
                                    lengthScale,
                                    noiseWScale,
                                ]),
                                [3]
                            ),
                        };

                        // Add speaker ID for multi-speaker models
                        if (this.voiceConfig.num_speakers > 1) {
                            inputs["sid"] = new ort.Tensor(
                                "int64",
                                BigInt64Array.from([BigInt(speakerId)]),
                                [1]
                            );
                        }

                        const results = await this.session.run(inputs);

                        // Extract audio data
                        const audioOutput = results.output;
                        const audioData = audioOutput.data;

                        // Use the sample rate from config
                        const sampleRate = this.voiceConfig.audio.sample_rate;

                        // Clean up audio data
                        const finalAudioData = new Float32Array(audioData);

                        yield {
                            text,
                            audio: new RawAudio(finalAudioData, sampleRate),
                        };
                    }
                } catch (error) {
                    console.error("Error generating audio:", error);
                    // Yield silence in case of error
                    yield {
                        text,
                        audio: new RawAudio(new Float32Array(22050), 22050),
                    };
                }
            }
        }
    }

    // Get available speakers for multi-speaker models
    getSpeakers() {
        if (!this.voiceConfig || this.voiceConfig.num_speakers <= 1) {
            return [{ id: 0, name: "Voice 1" }];
        }

        const speakerIdMap = this.voiceConfig.speaker_id_map || {};
        return Object.entries(speakerIdMap)
            .sort(([, a], [, b]) => a - b) // Sort by speaker ID (0, 1, 2, ...)
            .map(([originalId, id]) => ({
                id,
                name: `Voice ${id + 1}`,
                originalId,
            }));
    }
}
